#- name: Create service account for Spark
#  user: name={{ spark.user }}
#        system=yes
#        shell={{ spark.user_shell }}
#        state=present
#        groups="{{ spark.user_groups | join(',') }}"
- name: ensure tar is present
  package:
    name: "{{ item }}"
    state: present
  with_items:
  - tar
  - unzip
  become: yes

- name: create install directory
  file:
    path: "{{ spark_installation_dir }}"
    state: directory
#    owner: "{{ spark.user }}"
#    group: "{{ spark.user }}"
  become: true

- name: stop spark
  shell: "sbin/stop-all.sh"
  args:
      chdir: "{{ spark_installation_dir }}"
  ignore_errors: yes
  when: inventory_hostname in groups['master']

- name: download spark
  get_url: 
    url: "{{ spark_download }}" 
    dest: "/tmp/{{ spark_archive }}"
    use_proxy: no

- name: unarchive to the install directory
  unarchive:
    src: /tmp/{{ spark_archive }}
    dest: "{{ spark_installation_dir }}"
    remote_src: true
    extra_opts:
    - "--strip-components=1"

- name: create spark working directory
  file:
    path: "{{ spark.working_dir }}"
    state: directory
#    owner: "{{ spark.user }}"
#    group: "{{ spark.user }}"
  become: true

- name: set spark-env.sh
  template:
    src: "spark-env-sh.j2"
    dest: "{{ spark_installation_dir }}/conf/spark-env.sh"

- name: set spark-defaults.conf
  template:
    src: "spark-defaults-conf.j2"
    dest: "{{ spark_installation_dir }}/conf/spark-defaults.conf"

- name: set slaves
  template:
    src: "slaves.j2"
    dest: "{{ spark_installation_dir }}/conf/slaves"
  when: spark_num_workers| int >= 2

# Environment setup.
- name: add spark profile to startup
  template:
    src: spark-profile.sh.j2
    dest: /etc/profile.d/spark-profile.sh
    mode: 0644

- name: start-cluster utility
  template:
    src: "spark-cluster.sh.j2"
    dest: "{{ spark_installation_dir}}/bin/spark-cluster.sh"
    mode: 0744
  #when: is_master
